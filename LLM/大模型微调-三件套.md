一 P-tuning
1.Prefix-Tuning思想：
	a.在每一层token之前构造一段任务相关的tokens作为Prefix，训练时只更新Prefix部分的参数，而Transformer中其他部分参数固定
	b.一个Prefix模块就是一个可学习的id到embedding映射表，可在多层分别添加Prefix模块
	c.为了防止直接更新Prefix的参数导致训练不稳定的情况，在Prefix层前面增加MLP结构
	d.作用阶段:所有Transformer block的attention注意力计算
	示图
		![[Prefix示例.png]]

2 Prompt-Tuning思想：
	a.可视为Prefix-Tuning的简化版，只在输入层加入prompt token，并不需要加入MLP进行调整
	b.提出prompt Ensembling方法来集成预训练语言模型的多种prompts
	c.只额外增加3.6%参数规模的情况下取得和全微调接近的效果
	d.作用阶段：第一层transformer block的注意力计算
	示图 
		![[Pasted image 20230825005640.png]]

3.虚拟token只做K V，不做Q
4.大模型的prefixtuing的微调 都是用 transformers提供的peft库
	但是清华的chatglm系列，采用了特殊的结构，和自由的命名规范 导致 可以用lora，但是不能用prefix-tuning
5.代码
finetune_prompt.py
--pre_sql_len 128:给原生的每层加上128的软token
modeling_chatglm.py
![[modeling_chatglm 2.py]]
示例
	![[Pasted image 20230825011709.png]]
	![[Pasted image 20230825011912.png]]
二 适配器
1.结构
	![[Pasted image 20230825013428.png]]
为一resnet结构，微调时只微调adapter

2.chatglm,peft都没有实现
3.代码：finetune_adapter.py
![[finetune_adapter.py]]
示例：
	![[Pasted image 20230825015355.png]]
	![[Pasted image 20230825014843.png]]
	
	 
 
4.适配器需单独保存，加载
	保存：
	![[Pasted image 20230825015817.png]]
	加载：（手动改结构拼接）
	![[Pasted image 20230825020024.png]] 

三 Lora
1.结构
	![[Pasted image 20230826171919.png]] 

2.r:线性代数中矩阵的秩（矩阵实际的维度）
好处：节约内存

3.初始化：为了模型一开始保持原状，初始化W0=A B=0，A=0 or B=0,一个正态分布，一个为0，但不能同时为0（梯度为0，参数不更新）
	![[Pasted image 20230826172606.png]]

4.参数量：原：h=Wx (h:m* 1,x:n* 1)
lora:W0=A B (m* r+n* r<<mn)
r=4,8,16 领域越垂直，r越大，参数越多，可学习的信息越多；
越泛化通用，r越小；
r过大，对原有模型破坏越严重->产生灾难性遗忘（P-Tuning，Adapter也一样）

5.Lora作用于：attention中的Wq,Wk,Wv，
由于attention基本思想是v的加权求和，加权权重由q,k决定，改变权重时，调整两个和调整一个的效果是一样的，因此只需要改变一个矩阵（Wq,Wk二选一）

6.计算量并没有减少，但速度确更快，原因：
1、只更新了部分参数：比如LoRA原论文就选择只更新Self Attention的参数， 实际使用时我们还可以选择只更新部分层的参数；
2、减少了通信时间：由于更新的参数量变少了，所以（尤其是多卡训练时）要 传输的数据量也变少了，从而减少了传输时间；
3、采用了各种低精度加速技术，如FP16、FP8或者INT8量化等。

内存占用粗略公式：6x可训练参数+2x不可训练参数

7 代码
![[finetune_lora.py]]

 示例：
	![[Pasted image 20230826175249.png]]
来源peft：peft.get_peft_model
inference_mode:推理模式，是否训练；
lora_alpha:W0前面的系数，Lora的权重（W+W0->W+alpha* W0）

四 Langchain——人工构造prompt工程
1.方法：构造一个知识库 
知识来源：pdf ocr word->纯文本 
知识类型：qa问答对，非结构化纯文本 知识向量化（bert模型）：qa问答对的问题向量化 ，非结构化文本直接向量化


2.示例
庐山有什么好玩的
在向量库检索最相似的知识，放在前面做prompt

3代码
![[generate_vector.py]]

![[test_langchain.py]]

4.总结：Langchain 利用向量检索，搜寻知识库，拼接prompt 并不会对模型进行改变 
优势：简单，计算资源也少，也不需要训练，只需构建知识库 
缺点：上限取决于模型本身能力。迁移性差，不同模型需要构造不同prompt

5.模型输入长度有限，如果知识过长，需要内容压缩。给模型训练不曾见过（信息量高）的知识，效果才好。
	句子s，模型生成s的概率越低，s带来的信息量越大，信息量-log p。
	
![[compress.py]]

如何生成一句话的概率：
chatglm输入输出：
	![[Pasted image 20230826222938.png]]
思想：让一个空输入输出这句话
	![[Pasted image 20230826223047.png]]
	计算输出和目标之间各token的（信息熵）loss，取平均
压缩：在相似句子中，优先选择信息熵（loss）高的句子

6.总结微调方法
截止目前 
Lora 最常用，最好用的方法 
Langchain：门槛最低，最容易的方法 
Ptuning，直接微调
adapter：占用资源相对较多，用的相对较